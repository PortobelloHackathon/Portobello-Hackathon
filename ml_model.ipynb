{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebeb15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# üß± TILE LINE ‚Äî VARIOUS PREDICTIONS + ACCURACY + STAGE FLAGS + SHAP XAI\n",
    "#\n",
    "# ‚úÖ What this does\n",
    "# - Trains ML models (RandomForest) to predict stage ratios:\n",
    "#     press_ratio = vol_press_out  / vol_start\n",
    "#     glaze_ratio = vol_glaze_out  / vol_press_out\n",
    "#     kiln_ratio  = vol_kiln_out   / vol_glaze_out\n",
    "# - Creates a TEST set with mixed starting points (Start / Press / Glaze / Kiln / Full).\n",
    "# - Predicts ONLY forward-missing stages.\n",
    "# - Builds per-stage ‚Äúminimum required‚Äù = (predicted ratio - 0.03), clipped to [0,1].\n",
    "# - Hard rule for Sort ONLY: minimum ratio = 0.90 (no ML for Sort).\n",
    "# - Flags rows where a *predicted* stage falls below its min (e.g., LOW_KILN_YIELD).\n",
    "# - Optionally explains flagged *ML* stages with SHAP (top negative contributors).\n",
    "#\n",
    "# üì¶ Artifacts written:\n",
    "#   - tiles_staged_test_input.csv          (masked test)\n",
    "#   - tiles_staged_test_predictions.csv    (filled predictions)\n",
    "#   - tiles_predictions_friendly.csv       (human-friendly per-row report)\n",
    "#   - tiles_predictions_compact.txt/.csv   (one-line summaries)\n",
    "#   - tiles_predictions_eval.csv           (per-stage eval vs ACTUAL)\n",
    "#   - tiles_flags_only.csv                 (rows with any stage flag, NO hardcoded spec flags)\n",
    "#   - tiles_predictions_explanations.csv   (SHAP top negative features, if shap installed)\n",
    "#   - tiles_predictions_explanations.json  (same in JSON, if shap installed)\n",
    "#   - tile_models_bundle.joblib            (bundle to load in your UI service)\n",
    "# =========================================\n",
    "\n",
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# ---------- SHAP (Explainability) ----------\n",
    "HAS_SHAP = False\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] SHAP not installed; skipping XAI. Install with: pip install shap\")\n",
    "    shap = None\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "DATA_PATH   = \"tiles6.csv\"   # <--- your input file\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE    = 0.15\n",
    "\n",
    "# Staged masking mix (sum to 1.0):\n",
    "# 0 = Start only, 1 = up to Press, 2 = up to Glaze, 3 = up to Kiln, 4 = Full known\n",
    "MASK_PROBS = [0.30, 0.25, 0.25, 0.15, 0.05]\n",
    "\n",
    "# Sort policy (ONLY hard-coded flag)\n",
    "SORT_MIN     = 0.90\n",
    "SORT_DEFAULT = 0.90\n",
    "SORT_MAX     = 0.92\n",
    "\n",
    "# per-stage min margin around ML predictions\n",
    "THRESHOLD_MARGIN = 0.03\n",
    "\n",
    "# filenames\n",
    "OUT_MASKED     = \"tiles_staged_test_input.csv\"\n",
    "OUT_PRED       = \"tiles_staged_test_predictions.csv\"\n",
    "OUT_FRIENDLY   = \"tiles_predictions_friendly.csv\"\n",
    "OUT_COMPACT_C  = \"tiles_predictions_compact.csv\"\n",
    "OUT_COMPACT_T  = \"tiles_predictions_compact.txt\"\n",
    "OUT_EVAL       = \"tiles_predictions_eval.csv\"\n",
    "FLAGS_ONLY_OUT = \"tiles_flags_only.csv\"\n",
    "XAI_OUT_CSV    = \"tiles_predictions_explanations.csv\"\n",
    "XAI_OUT_JSON   = \"tiles_predictions_explanations.json\"\n",
    "BUNDLE_PATH    = \"tile_models_bundle.joblib\"\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def safe_ratio(num, den):\n",
    "    num = pd.to_numeric(num, errors=\"coerce\")\n",
    "    den = pd.to_numeric(den, errors=\"coerce\")\n",
    "    r = np.where((den <= 0) | pd.isna(den), np.nan, num / den)\n",
    "    return np.clip(r, 0.0, 1.0)\n",
    "\n",
    "def clip01(x):\n",
    "    return np.minimum(1.0, np.maximum(0.0, x))\n",
    "\n",
    "def volume_from_ratio(prev_vol, ratio, round_to_int=True):\n",
    "    v = prev_vol * ratio\n",
    "    return np.rint(v) if round_to_int else v\n",
    "\n",
    "def as_int_nullable(values):\n",
    "    s = pd.Series(values)\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.round().astype(\"Int64\")\n",
    "\n",
    "def met_min_str(pred_mask, actual_series, minreq_series):\n",
    "    actual = pd.to_numeric(actual_series, errors=\"coerce\").astype(float)\n",
    "    minreq = pd.to_numeric(minreq_series,  errors=\"coerce\").astype(float)\n",
    "    a = actual.to_numpy()\n",
    "    m = minreq.to_numpy()\n",
    "    pred_arr = np.asarray(pred_mask, dtype=bool)\n",
    "    has_both = (~np.isnan(a)) & (~np.isnan(m))\n",
    "    met = a >= m\n",
    "    out = np.full(len(pred_arr), \"\", dtype=object)\n",
    "    idx = pred_arr\n",
    "    out[idx] = np.where(has_both[idx], np.where(met[idx], \"YES\", \"NO\"), \"\")\n",
    "    return pd.Series(out, index=actual_series.index)\n",
    "\n",
    "def fmt_int(x):\n",
    "    try:\n",
    "        v = pd.to_numeric(x)\n",
    "        if pd.isna(v): return \"-\"\n",
    "        return f\"{int(round(float(v))):,}\"\n",
    "    except Exception:\n",
    "        return \"-\"\n",
    "\n",
    "# -----------------------\n",
    "# HARD-CODED RECIPE SETPOINTS (memory for features only)\n",
    "# -----------------------\n",
    "RECIPE_SETPOINTS = {\n",
    "    241: dict(k_set_max_temp=1197.0, k_set_cooling=5.2, k_set_moisture=6.0,\n",
    "              k_set_humidity=50.0, k_set_air_flow=6.0, k_set_air_cooling=5.0, k_set_thickness_mm=8.5),\n",
    "    244: dict(k_set_max_temp=1195.0, k_set_cooling=5.0, k_set_moisture=6.0,\n",
    "              k_set_humidity=48.0, k_set_air_flow=5.8, k_set_air_cooling=5.1, k_set_thickness_mm=8.5),\n",
    "    245: dict(k_set_max_temp=1196.0, k_set_cooling=5.3, k_set_moisture=6.0,\n",
    "              k_set_humidity=52.0, k_set_air_flow=6.2, k_set_air_cooling=4.9, k_set_thickness_mm=8.5),\n",
    "    246: dict(k_set_max_temp=1194.0, k_set_cooling=4.9, k_set_moisture=6.0,\n",
    "              k_set_humidity=47.0, k_set_air_flow=5.7, k_set_air_cooling=5.2, k_set_thickness_mm=8.5),\n",
    "    247: dict(k_set_max_temp=1198.0, k_set_cooling=5.1, k_set_moisture=6.0,\n",
    "              k_set_humidity=49.0, k_set_air_flow=6.1, k_set_air_cooling=5.0, k_set_thickness_mm=8.5),\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# 1) LOAD\n",
    "# -----------------------\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"datetime\"])\n",
    "print(f\"Loaded {len(df)} rows from {DATA_PATH}\")\n",
    "\n",
    "required_cols = [\n",
    "    \"datetime\",\"vol_start\",\n",
    "    \"pressure_psi\",\"vol_press_out\",\n",
    "    \"recipe_id\",\"vol_glaze_out\",\n",
    "    \"max_temp\",\"cooling_profile\",\"moisture_pct\",\"external_humidity\",\n",
    "    \"air_flow_top_setting\",\"air_cooling\",\"thickness_mm\",\"vol_kiln_out\",\n",
    "    \"vol_sort_out\"\n",
    "]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# enforce monotonic safety\n",
    "df[\"vol_press_out\"] = np.minimum(df[\"vol_press_out\"], df[\"vol_start\"])\n",
    "df[\"vol_glaze_out\"] = np.minimum(df[\"vol_glaze_out\"], df[\"vol_press_out\"])\n",
    "df[\"vol_kiln_out\"]  = np.minimum(df[\"vol_kiln_out\"],  df[\"vol_glaze_out\"])\n",
    "df[\"vol_sort_out\"]  = np.minimum(df[\"vol_sort_out\"],  df[\"vol_kiln_out\"])\n",
    "\n",
    "# attach setpoints + deltas\n",
    "sp = pd.DataFrame.from_dict(RECIPE_SETPOINTS, orient=\"index\").reset_index().rename(columns={\"index\":\"recipe_id\"})\n",
    "df = df.merge(sp, on=\"recipe_id\", how=\"left\")\n",
    "\n",
    "df[\"delta_max_temp\"]    = df[\"max_temp\"]             - df[\"k_set_max_temp\"]\n",
    "df[\"delta_cooling\"]     = df[\"cooling_profile\"]      - df[\"k_set_cooling\"]\n",
    "df[\"delta_moisture\"]    = df[\"moisture_pct\"]         - df[\"k_set_moisture\"]\n",
    "df[\"delta_humidity\"]    = df[\"external_humidity\"]    - df[\"k_set_humidity\"]\n",
    "df[\"delta_air_flow\"]    = df[\"air_flow_top_setting\"] - df[\"k_set_air_flow\"]\n",
    "df[\"delta_air_cooling\"] = df[\"air_cooling\"]          - df[\"k_set_air_cooling\"]\n",
    "\n",
    "# targets\n",
    "df[\"press_ratio\"] = safe_ratio(df[\"vol_press_out\"], df[\"vol_start\"])\n",
    "df[\"glaze_ratio\"] = safe_ratio(df[\"vol_glaze_out\"], df[\"vol_press_out\"])\n",
    "df[\"kiln_ratio\"]  = safe_ratio(df[\"vol_kiln_out\"],  df[\"vol_glaze_out\"])\n",
    "df[\"sort_ratio\"]  = safe_ratio(df[\"vol_sort_out\"],  df[\"vol_kiln_out\"])\n",
    "\n",
    "# -----------------------\n",
    "# 2) FEATURE SETS\n",
    "# -----------------------\n",
    "PRESS_FEATS = [\"vol_start\", \"pressure_psi\", \"recipe_id\"]\n",
    "GLAZE_FEATS = [\"recipe_id\", \"vol_press_out\", \"pressure_psi\"]\n",
    "KILN_FEATS  = [\n",
    "    \"recipe_id\", \"vol_glaze_out\",\n",
    "    \"k_set_max_temp\",\"k_set_cooling\",\"k_set_moisture\",\"k_set_humidity\",\n",
    "    \"k_set_air_flow\",\"k_set_air_cooling\",\"k_set_thickness_mm\",\n",
    "    \"max_temp\",\"cooling_profile\",\"moisture_pct\",\"external_humidity\",\n",
    "    \"air_flow_top_setting\",\"air_cooling\",\"thickness_mm\",\n",
    "    \"delta_max_temp\",\"delta_cooling\",\"delta_moisture\",\"delta_humidity\",\n",
    "    \"delta_air_flow\",\"delta_air_cooling\"\n",
    "]\n",
    "STAGE_TO_FEATS = {\n",
    "    \"press_ratio\": PRESS_FEATS,\n",
    "    \"glaze_ratio\": GLAZE_FEATS,\n",
    "    \"kiln_ratio\":  KILN_FEATS,\n",
    "}\n",
    "\n",
    "def make_pipe(feat_cols):\n",
    "    cat_cols = [c for c in feat_cols if c == \"recipe_id\"]\n",
    "    num_cols = [c for c in feat_cols if c not in cat_cols]\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=500, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    return Pipeline([(\"pre\", pre), (\"rf\", model)])\n",
    "\n",
    "# -----------------------\n",
    "# 3) TRAIN / TEST SPLIT\n",
    "# -----------------------\n",
    "train_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df  = test_df.reset_index(drop=True)\n",
    "print(f\"Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# -----------------------\n",
    "# 4) FIT MODELS\n",
    "# -----------------------\n",
    "models = {}\n",
    "for target, feats in STAGE_TO_FEATS.items():\n",
    "    tdf = train_df.copy()\n",
    "    mask = ~tdf[target].isna()\n",
    "    X = tdf.loc[mask, feats]\n",
    "    y = tdf.loc[mask, target]\n",
    "    pipe = make_pipe(feats)\n",
    "    pipe.fit(X, y)\n",
    "    models[target] = pipe\n",
    "    y_pred = clip01(pipe.predict(X))\n",
    "    print(f\"[FIT] {target}: R2={r2_score(y, y_pred):.3f} MAE={mean_absolute_error(y, y_pred):.4f} n={len(X)}\")\n",
    "\n",
    "# -----------------------\n",
    "# 5) STAGED MASKING (various prediction starting points)\n",
    "# -----------------------\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "levels = rng.choice([0,1,2,3,4], size=len(test_df), p=MASK_PROBS)\n",
    "masked = test_df.copy()\n",
    "masked[\"known_level\"] = levels\n",
    "\n",
    "for i, lvl in enumerate(levels):\n",
    "    if lvl < 1:\n",
    "        masked.loc[i, [\"vol_press_out\",\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\"]] = np.nan\n",
    "    elif lvl < 2:\n",
    "        masked.loc[i, [\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\"]] = np.nan\n",
    "    elif lvl < 3:\n",
    "        masked.loc[i, [\"vol_kiln_out\",\"vol_sort_out\"]] = np.nan\n",
    "    elif lvl < 4:\n",
    "        masked.loc[i, [\"vol_sort_out\"]] = np.nan\n",
    "\n",
    "truth = test_df[[\"vol_start\",\"vol_press_out\",\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\"]].copy()\n",
    "\n",
    "print(\"\\nMasked start-points (test):\")\n",
    "print(pd.Series(levels).map({0:\"Start\",1:\"Press\",2:\"Glaze\",3:\"Kiln\",4:\"Full\"}).value_counts().sort_index().to_string())\n",
    "\n",
    "# -----------------------\n",
    "# 6) PREDICT ONLY MISSING FORWARD\n",
    "# -----------------------\n",
    "pred = masked.copy()\n",
    "\n",
    "def predict_stage(mdf, stage_key, feat_cols, prev_col, out_col):\n",
    "    need = mdf[out_col].isna() & mdf[prev_col].notna()\n",
    "    if need.any():\n",
    "        r = clip01(models[stage_key].predict(mdf.loc[need, feat_cols]))\n",
    "        mdf.loc[need, f\"{stage_key}_pred\"] = r\n",
    "        mdf.loc[need, f\"{stage_key}_min\"]  = clip01(r - THRESHOLD_MARGIN)\n",
    "        mdf.loc[need, f\"{out_col}_pred\"] = volume_from_ratio(mdf.loc[need, prev_col].values, r, round_to_int=True)\n",
    "        mdf.loc[need, out_col] = mdf.loc[need, f\"{out_col}_pred\"]\n",
    "    return mdf\n",
    "\n",
    "# Press\n",
    "pred = predict_stage(pred, \"press_ratio\", PRESS_FEATS, prev_col=\"vol_start\",     out_col=\"vol_press_out\")\n",
    "pred[\"vol_press_out\"] = np.minimum(pred[\"vol_press_out\"], pred[\"vol_start\"])\n",
    "# Glaze\n",
    "pred = predict_stage(pred, \"glaze_ratio\", GLAZE_FEATS, prev_col=\"vol_press_out\", out_col=\"vol_glaze_out\")\n",
    "pred[\"vol_glaze_out\"] = np.minimum(pred[\"vol_glaze_out\"], pred[\"vol_press_out\"])\n",
    "# Kiln\n",
    "pred = predict_stage(pred, \"kiln_ratio\",  KILN_FEATS,  prev_col=\"vol_glaze_out\", out_col=\"vol_kiln_out\")\n",
    "pred[\"vol_kiln_out\"]  = np.minimum(pred[\"vol_kiln_out\"],  pred[\"vol_glaze_out\"])\n",
    "# Sort (rule, only hard-coded threshold here)\n",
    "need_sort = pred[\"vol_sort_out\"].isna() & pred[\"vol_kiln_out\"].notna()\n",
    "if need_sort.any():\n",
    "    r = np.clip(np.full(need_sort.sum(), SORT_DEFAULT), SORT_MIN, SORT_MAX)\n",
    "    pred.loc[need_sort, \"sort_ratio_pred\"] = r\n",
    "    pred.loc[need_sort, \"sort_ratio_min\"]  = SORT_MIN\n",
    "    pred.loc[need_sort, \"vol_sort_out_pred\"] = volume_from_ratio(pred.loc[need_sort, \"vol_kiln_out\"].values, r, round_to_int=True)\n",
    "    pred.loc[need_sort, \"vol_sort_out\"] = pred.loc[need_sort, \"vol_sort_out_pred\"]\n",
    "pred[\"vol_sort_out\"] = np.minimum(pred[\"vol_sort_out\"], pred[\"vol_kiln_out\"])\n",
    "\n",
    "# -----------------------\n",
    "# 7) ACCURACY (predicted rows only)\n",
    "# -----------------------\n",
    "def stage_metrics(stage_out, base_col, pred_out_col):\n",
    "    tr = safe_ratio(truth[stage_out].to_numpy(), truth[base_col].to_numpy())\n",
    "    pr = safe_ratio(pred[stage_out].to_numpy(),  pred[base_col].to_numpy())\n",
    "    if pred_out_col not in pred.columns:\n",
    "        return dict(n=0, R2=np.nan, MAE=np.nan)\n",
    "    mask = pred[pred_out_col].notna()\n",
    "    if mask.any():\n",
    "        return dict(n=int(mask.sum()),\n",
    "                    R2=float(r2_score(tr[mask], pr[mask])),\n",
    "                    MAE=float(mean_absolute_error(tr[mask], pr[mask])))\n",
    "    return dict(n=0, R2=np.nan, MAE=np.nan)\n",
    "\n",
    "print(\"\\n=== ACCURACY (predicted rows only) ===\")\n",
    "print(\"Press:\", stage_metrics(\"vol_press_out\", \"vol_start\",     \"vol_press_out_pred\"))\n",
    "print(\"Glaze:\", stage_metrics(\"vol_glaze_out\", \"vol_press_out\", \"vol_glaze_out_pred\"))\n",
    "print(\"Kiln :\", stage_metrics(\"vol_kiln_out\",  \"vol_glaze_out\", \"vol_kiln_out_pred\"))\n",
    "\n",
    "# -----------------------\n",
    "# 8) REALIZED RATIOS & STAGE FLAGS\n",
    "# -----------------------\n",
    "pred[\"press_ratio_real\"] = safe_ratio(pred[\"vol_press_out\"], pred[\"vol_start\"])\n",
    "pred[\"glaze_ratio_real\"] = safe_ratio(pred[\"vol_glaze_out\"], pred[\"vol_press_out\"])\n",
    "pred[\"kiln_ratio_real\"]  = safe_ratio(pred[\"vol_kiln_out\"],  pred[\"vol_glaze_out\"])\n",
    "pred[\"sort_ratio_real\"]  = safe_ratio(pred[\"vol_sort_out\"],  pred[\"vol_kiln_out\"])\n",
    "\n",
    "for nm in [\"press_ratio_min\",\"glaze_ratio_min\",\"kiln_ratio_min\",\"sort_ratio_min\"]:\n",
    "    if nm not in pred.columns: pred[nm] = np.nan\n",
    "pred.loc[pred[\"vol_kiln_out\"].notna(), \"sort_ratio_min\"] = SORT_MIN\n",
    "\n",
    "pred[\"press_flag\"] = np.where(\n",
    "    (pred[\"press_ratio_min\"].notna()) & (pred[\"press_ratio_real\"] < pred[\"press_ratio_min\"]),\n",
    "    \"LOW_PRESS_YIELD\", \"\"\n",
    ")\n",
    "pred[\"glaze_flag\"] = np.where(\n",
    "    (pred[\"glaze_ratio_min\"].notna()) & (pred[\"glaze_ratio_real\"] < pred[\"glaze_ratio_min\"]),\n",
    "    \"LOW_GLAZE_YIELD\", \"\"\n",
    ")\n",
    "pred[\"kiln_flag\"] = np.where(\n",
    "    (pred[\"kiln_ratio_min\"].notna()) & (pred[\"kiln_ratio_real\"] < pred[\"kiln_ratio_min\"]),\n",
    "    \"LOW_KILN_YIELD\", \"\"\n",
    ")\n",
    "pred[\"sort_flag\"] = np.where(pred[\"sort_ratio_real\"] < SORT_MIN, \"SORT_BELOW_90\", \"\")\n",
    "\n",
    "# -----------------------\n",
    "# 9) FRIENDLY REPORT (known vs predicted + min + flag + correctness)\n",
    "# -----------------------\n",
    "LEVEL_LABELS = {0:\"Start only\",1:\"Up to Press\",2:\"Up to Glaze\",3:\"Up to Kiln\",4:\"Full known\"}\n",
    "press_known = masked[\"vol_press_out\"].notna()\n",
    "glaze_known = masked[\"vol_glaze_out\"].notna()\n",
    "kiln_known  = masked[\"vol_kiln_out\"].notna()\n",
    "sort_known  = masked[\"vol_sort_out\"].notna()\n",
    "press_pred  = pred[\"vol_press_out_pred\"].notna()\n",
    "glaze_pred  = pred[\"vol_glaze_out_pred\"].notna()\n",
    "kiln_pred   = pred[\"vol_kiln_out_pred\"].notna()\n",
    "sort_pred   = pred[\"vol_sort_out_pred\"].notna()\n",
    "\n",
    "press_min_vol_num = pred[\"press_ratio_min\"] * pred[\"vol_start\"]\n",
    "glaze_min_vol_num = pred[\"glaze_ratio_min\"] * pred[\"vol_press_out\"]\n",
    "kiln_min_vol_num  = pred[\"kiln_ratio_min\"]  * pred[\"vol_glaze_out\"]\n",
    "sort_min_vol_num  = SORT_MIN * pred[\"vol_kiln_out\"]\n",
    "\n",
    "friendly = pd.DataFrame({\n",
    "    \"datetime\": pred[\"datetime\"],\n",
    "    \"recipe_id\": pred[\"recipe_id\"],\n",
    "    \"known_level\": pred[\"known_level\"],\n",
    "    \"known_level_label\": pd.Series(pred[\"known_level\"]).map(LEVEL_LABELS),\n",
    "    \"START_amount_ft2\": as_int_nullable(pred[\"vol_start\"]),\n",
    "})\n",
    "\n",
    "# PRESS\n",
    "friendly[\"PRESS_status\"]               = np.where(press_known, \"known\", np.where(press_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"PRESS_known_amount_ft2\"]     = as_int_nullable(np.where(press_known, pred[\"vol_press_out\"], np.nan))\n",
    "friendly[\"PRESS_predicted_amount_ft2\"] = as_int_nullable(np.where(press_pred,  pred[\"vol_press_out_pred\"], np.nan))\n",
    "friendly[\"PRESS_min_required_ft2\"]     = as_int_nullable(np.where(press_pred,  press_min_vol_num, np.nan))\n",
    "friendly[\"PRESS_flag\"]                 = np.where(press_pred,  pred[\"press_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"PRESS_actual_ft2\"]           = as_int_nullable(truth[\"vol_press_out\"])\n",
    "friendly[\"PRESS_met_min\"]              = met_min_str(press_pred, friendly[\"PRESS_actual_ft2\"], friendly[\"PRESS_min_required_ft2\"])\n",
    "\n",
    "# GLAZE\n",
    "friendly[\"GLAZE_status\"]               = np.where(glaze_known, \"known\", np.where(glaze_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"GLAZE_known_amount_ft2\"]     = as_int_nullable(np.where(glaze_known, pred[\"vol_glaze_out\"], np.nan))\n",
    "friendly[\"GLAZE_predicted_amount_ft2\"] = as_int_nullable(np.where(glaze_pred,  pred[\"vol_glaze_out_pred\"], np.nan))\n",
    "friendly[\"GLAZE_min_required_ft2\"]     = as_int_nullable(np.where(glaze_pred,  glaze_min_vol_num, np.nan))\n",
    "friendly[\"GLAZE_flag\"]                 = np.where(glaze_pred,  pred[\"glaze_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"GLAZE_actual_ft2\"]           = as_int_nullable(truth[\"vol_glaze_out\"])\n",
    "friendly[\"GLAZE_met_min\"]              = met_min_str(glaze_pred, friendly[\"GLAZE_actual_ft2\"], friendly[\"GLAZE_min_required_ft2\"])\n",
    "\n",
    "# KILN\n",
    "friendly[\"KILN_status\"]               = np.where(kiln_known, \"known\", np.where(kiln_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"KILN_known_amount_ft2\"]     = as_int_nullable(np.where(kiln_known, pred[\"vol_kiln_out\"], np.nan))\n",
    "friendly[\"KILN_predicted_amount_ft2\"] = as_int_nullable(np.where(kiln_pred,  pred[\"vol_kiln_out_pred\"], np.nan))\n",
    "friendly[\"KILN_min_required_ft2\"]     = as_int_nullable(np.where(kiln_pred,  kiln_min_vol_num, np.nan))\n",
    "friendly[\"KILN_flag\"]                 = np.where(kiln_pred,  pred[\"kiln_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"KILN_actual_ft2\"]           = as_int_nullable(truth[\"vol_kiln_out\"])\n",
    "friendly[\"KILN_met_min\"]              = met_min_str(kiln_pred, friendly[\"KILN_actual_ft2\"], friendly[\"KILN_min_required_ft2\"])\n",
    "\n",
    "# SORT (rule)\n",
    "friendly[\"SORT_status\"]               = np.where(sort_known, \"known\", np.where(sort_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"SORT_known_amount_ft2\"]     = as_int_nullable(np.where(sort_known, pred[\"vol_sort_out\"], np.nan))\n",
    "friendly[\"SORT_predicted_amount_ft2\"] = as_int_nullable(np.where(sort_pred,  pred[\"vol_sort_out_pred\"], np.nan))\n",
    "friendly[\"SORT_min_required_ft2\"]     = as_int_nullable(np.where(sort_pred,  sort_min_vol_num, np.nan))\n",
    "friendly[\"SORT_flag\"]                 = np.where(sort_pred,  pred[\"sort_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"SORT_actual_ft2\"]           = as_int_nullable(truth[\"vol_sort_out\"])\n",
    "friendly[\"SORT_met_min\"]              = met_min_str(sort_pred, friendly[\"SORT_actual_ft2\"], friendly[\"SORT_min_required_ft2\"])\n",
    "\n",
    "friendly = friendly.sort_values(\"datetime\").reset_index(drop=True)\n",
    "friendly.to_csv(OUT_FRIENDLY, index=False)\n",
    "print(f\"\\nWrote friendly per-row report:\\n - {OUT_FRIENDLY}\")\n",
    "\n",
    "# -----------------------\n",
    "# 10) COMPACT ONE-LINE SUMMARY PER ROW\n",
    "# -----------------------\n",
    "def min_volumes_row(row):\n",
    "    press_min = row.get(\"press_ratio_min\", np.nan) * row.get(\"vol_start\", np.nan)\n",
    "    glaze_min = row.get(\"glaze_ratio_min\", np.nan) * row.get(\"vol_press_out\", np.nan)\n",
    "    kiln_min  = row.get(\"kiln_ratio_min\",  np.nan) * row.get(\"vol_glaze_out\", np.nan)\n",
    "    sort_min  = SORT_MIN * row.get(\"vol_kiln_out\", np.nan)\n",
    "    return press_min, glaze_min, kiln_min, sort_min\n",
    "\n",
    "def stage_piece(name, known_val, pred_val, min_vol):\n",
    "    known = not pd.isna(known_val)\n",
    "    predicted = not pd.isna(pred_val)\n",
    "    if known:\n",
    "        return f\"{name} = {fmt_int(known_val)}\"\n",
    "    if predicted:\n",
    "        return f\"{name} = {fmt_int(pred_val)} (pred), min {fmt_int(min_vol)}\"\n",
    "    return f\"{name} = -\"\n",
    "\n",
    "press_known_mask = masked[\"vol_press_out\"].notna()\n",
    "glaze_known_mask = masked[\"vol_glaze_out\"].notna()\n",
    "kiln_known_mask  = masked[\"vol_kiln_out\"].notna()\n",
    "sort_known_mask  = masked[\"vol_sort_out\"].notna()\n",
    "\n",
    "pred[\"__press_pred__\"] = pred[\"vol_press_out_pred\"].notna()\n",
    "pred[\"__glaze_pred__\"] = pred[\"vol_glaze_out_pred\"].notna()\n",
    "pred[\"__kiln_pred__\"]  = pred[\"vol_kiln_out_pred\"].notna()\n",
    "pred[\"__sort_pred__\"]  = pred[\"vol_sort_out_pred\"].notna()\n",
    "\n",
    "lines = []\n",
    "rows = []\n",
    "for i, row in pred.reset_index(drop=True).iterrows():\n",
    "    start_piece = f\"Start = {fmt_int(row['vol_start'])}\"\n",
    "    pmin, gmin, kmin, smin = min_volumes_row(row)\n",
    "\n",
    "    press_piece = stage_piece(\n",
    "        \"Press\",\n",
    "        known_val = pred.loc[i, \"vol_press_out\"] if press_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_press_out_pred\"] if pred[\"__press_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = pmin\n",
    "    )\n",
    "    glaze_piece = stage_piece(\n",
    "        \"Glaze\",\n",
    "        known_val = pred.loc[i, \"vol_glaze_out\"] if glaze_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_glaze_out_pred\"] if pred[\"__glaze_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = gmin\n",
    "    )\n",
    "    kiln_piece = stage_piece(\n",
    "        \"Kiln\",\n",
    "        known_val = pred.loc[i, \"vol_kiln_out\"] if kiln_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_kiln_out_pred\"] if pred[\"__kiln_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = kmin\n",
    "    )\n",
    "    sort_piece = stage_piece(\n",
    "        \"Sort\",\n",
    "        known_val = pred.loc[i, \"vol_sort_out\"] if sort_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_sort_out_pred\"] if pred[\"__sort_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = smin\n",
    "    )\n",
    "\n",
    "    summary = \"  \".join([start_piece, press_piece, glaze_piece, kiln_piece, sort_piece])\n",
    "    lines.append(summary)\n",
    "    rows.append({\"datetime\": row[\"datetime\"], \"recipe_id\": row[\"recipe_id\"], \"known_level\": row[\"known_level\"], \"summary\": summary})\n",
    "\n",
    "with open(OUT_COMPACT_T, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in lines:\n",
    "        f.write(s + \"\\n\")\n",
    "pd.DataFrame(rows).sort_values(\"datetime\").to_csv(OUT_COMPACT_C, index=False)\n",
    "print(f\"\\nWrote compact summaries:\\n - {OUT_COMPACT_T}\\n - {OUT_COMPACT_C}\")\n",
    "\n",
    "# -----------------------\n",
    "# 11) PER-STAGE EVAL vs ACTUAL\n",
    "# -----------------------\n",
    "def stage_eval(stage, base_col, out_col, pred_out_col, min_ratio_col, fixed_min=None):\n",
    "    if pred_out_col not in pred.columns:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"stage\",\"datetime\",\"recipe_id\",\n",
    "            \"predicted_amount_ft2\",\"min_required_ft2\",\"actual_amount_ft2\",\n",
    "            \"abs_error_ft2\",\"pct_error\",\"met_min\",\"flag_result\"\n",
    "        ])\n",
    "    m = pred[pred_out_col].notna()\n",
    "    if not m.any():\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"stage\",\"datetime\",\"recipe_id\",\n",
    "            \"predicted_amount_ft2\",\"min_required_ft2\",\"actual_amount_ft2\",\n",
    "            \"abs_error_ft2\",\"pct_error\",\"met_min\",\"flag_result\"\n",
    "        ])\n",
    "\n",
    "    min_ratio = pd.to_numeric(pred.loc[m, min_ratio_col], errors=\"coerce\") if fixed_min is None else pd.Series(fixed_min, index=pred.index)[m]\n",
    "    base = pd.to_numeric(pred.loc[m, base_col], errors=\"coerce\")\n",
    "    min_required = min_ratio * base\n",
    "\n",
    "    pred_amt = pd.to_numeric(pred.loc[m, pred_out_col], errors=\"coerce\")\n",
    "    actual_amt = pd.to_numeric(truth.loc[m, out_col], errors=\"coerce\")\n",
    "\n",
    "    abs_err = (pred_amt - actual_amt).abs()\n",
    "    pct_err = abs_err / actual_amt.replace({0: np.nan})\n",
    "\n",
    "    actual_ratio = actual_amt / base.replace({0: np.nan})\n",
    "    flag_result = np.where(actual_ratio < min_ratio, \"FLAG\", \"OK\")\n",
    "    met_min = np.where(actual_amt >= min_required, \"YES\", \"NO\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"stage\": stage,\n",
    "        \"datetime\": pred.loc[m, \"datetime\"],\n",
    "        \"recipe_id\": pred.loc[m, \"recipe_id\"],\n",
    "        \"predicted_amount_ft2\": pred_amt.round().astype(\"Int64\"),\n",
    "        \"min_required_ft2\": min_required.round().astype(\"Int64\"),\n",
    "        \"actual_amount_ft2\": actual_amt.round().astype(\"Int64\"),\n",
    "        \"abs_error_ft2\": abs_err.round().astype(\"Int64\"),\n",
    "        \"pct_error\": pct_err,\n",
    "        \"met_min\": met_min,\n",
    "        \"flag_result\": flag_result\n",
    "    })\n",
    "\n",
    "eval_press = stage_eval(\"PRESS\", base_col=\"vol_start\",     out_col=\"vol_press_out\",\n",
    "                        pred_out_col=\"vol_press_out_pred\", min_ratio_col=\"press_ratio_min\")\n",
    "eval_glaze = stage_eval(\"GLAZE\", base_col=\"vol_press_out\", out_col=\"vol_glaze_out\",\n",
    "                        pred_out_col=\"vol_glaze_out_pred\", min_ratio_col=\"glaze_ratio_min\")\n",
    "eval_kiln  = stage_eval(\"KILN\",  base_col=\"vol_glaze_out\", out_col=\"vol_kiln_out\",\n",
    "                        pred_out_col=\"vol_kiln_out_pred\",  min_ratio_col=\"kiln_ratio_min\")\n",
    "eval_sort  = stage_eval(\"SORT\",  base_col=\"vol_kiln_out\",  out_col=\"vol_sort_out\",\n",
    "                        pred_out_col=\"vol_sort_out_pred\",  min_ratio_col=\"sort_ratio_min\", fixed_min=SORT_MIN)\n",
    "\n",
    "eval_all = pd.concat([eval_press, eval_glaze, eval_kiln, eval_sort], ignore_index=True)\n",
    "eval_all.to_csv(OUT_EVAL, index=False)\n",
    "print(f\"\\nWrote per-stage evaluation vs ACTUAL:\\n - {OUT_EVAL}\")\n",
    "\n",
    "def summarize_stage(df_stage):\n",
    "    if df_stage.empty:\n",
    "        return \"n=0\"\n",
    "    n = len(df_stage)\n",
    "    mae  = pd.to_numeric(df_stage[\"abs_error_ft2\"], errors=\"coerce\").dropna()\n",
    "    mape = pd.to_numeric(df_stage[\"pct_error\"],     errors=\"coerce\").dropna()\n",
    "    comp = (df_stage[\"met_min\"] == \"YES\").mean() if n else np.nan\n",
    "    return f\"n={n}, MAE={mae.mean():.1f} ft¬≤, MAPE={(mape.mean()*100):.2f}%, compliance={comp*100:.1f}%\"\n",
    "\n",
    "print(\"\\n=== RESULTS vs ACTUAL (predicted rows) ===\")\n",
    "print(\"PRESS :\", summarize_stage(eval_press))\n",
    "print(\"GLAZE :\", summarize_stage(eval_glaze))\n",
    "print(\"KILN  :\", summarize_stage(eval_kiln))\n",
    "print(\"SORT  :\", summarize_stage(eval_sort))\n",
    "\n",
    "# Also write the filled test & masked inputs for reference\n",
    "pred.to_csv(OUT_PRED, index=False)\n",
    "masked.to_csv(OUT_MASKED, index=False)\n",
    "print(f\"\\nWrote:\\n - {OUT_MASKED}\\n - {OUT_PRED}\")\n",
    "\n",
    "# Quick friendly preview\n",
    "print(\"\\nFriendly preview (first 6 rows):\")\n",
    "cols = [\n",
    "    \"datetime\",\"recipe_id\",\"known_level_label\",\"START_amount_ft2\",\n",
    "    \"PRESS_status\",\"PRESS_known_amount_ft2\",\"PRESS_predicted_amount_ft2\",\"PRESS_min_required_ft2\",\"PRESS_flag\",\"PRESS_actual_ft2\",\"PRESS_met_min\",\n",
    "    \"GLAZE_status\",\"GLAZE_known_amount_ft2\",\"GLAZE_predicted_amount_ft2\",\"GLAZE_min_required_ft2\",\"GLAZE_flag\",\"GLAZE_actual_ft2\",\"GLAZE_met_min\",\n",
    "    \"KILN_status\",\"KILN_known_amount_ft2\",\"KILN_predicted_amount_ft2\",\"KILN_min_required_ft2\",\"KILN_flag\",\"KILN_actual_ft2\",\"KILN_met_min\",\n",
    "    \"SORT_status\",\"SORT_known_amount_ft2\",\"SORT_predicted_amount_ft2\",\"SORT_min_required_ft2\",\"SORT_flag\",\"SORT_actual_ft2\",\"SORT_met_min\",\n",
    "]\n",
    "print(friendly[cols].head(6).to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# 12) SHAP XAI (ONLY for ML stages; NO hardcoded spec flags)\n",
    "# -----------------------\n",
    "def get_ct_feature_names(preprocessor):\n",
    "    # Try to get nice feature names from ColumnTransformer\n",
    "    names = []\n",
    "    try:\n",
    "        names = preprocessor.get_feature_names_out()\n",
    "        names = [n.replace(\"num__\", \"\").replace(\"cat__\", \"\").replace(\"pre__\", \"\") for n in names]\n",
    "        names = [n.replace(\"cat__recipe_id_\", \"recipe_id=\").replace(\"recipe_id_\", \"recipe_id=\") for n in names]\n",
    "    except Exception:\n",
    "        # Fallback generic names\n",
    "        names = [f\"f{i}\" for i in range(\n",
    "            preprocessor.transform(pd.DataFrame([{}])).shape[1]\n",
    "        )]\n",
    "    return np.array(names)\n",
    "\n",
    "def top_negative_shap(pipeline, X_df, topk=5):\n",
    "    \"\"\"Return list of lists of (feature, shap_value) sorted by most negative for each row in X_df.\"\"\"\n",
    "    pre = pipeline.named_steps[\"pre\"]\n",
    "    rf  = pipeline.named_steps[\"rf\"]\n",
    "\n",
    "    X_t = pre.transform(X_df)\n",
    "    # dense array (TreeExplainer can use dense)\n",
    "    try:\n",
    "        X_t = X_t.toarray()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if not HAS_SHAP:\n",
    "        return [[] for _ in range(len(X_df))], None\n",
    "\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_vals = explainer.shap_values(X_t)  # (n_rows, n_features)\n",
    "    base_val  = explainer.expected_value\n",
    "\n",
    "    feat_names = get_ct_feature_names(pre)\n",
    "    feat_names = feat_names if len(feat_names) == X_t.shape[1] else np.array([f\"f{i}\" for i in range(X_t.shape[1])])\n",
    "\n",
    "    out = []\n",
    "    for i in range(X_t.shape[0]):\n",
    "        sv = shap_vals[i]\n",
    "        order = np.argsort(sv)  # ascending: most negative first\n",
    "        pairs = [(feat_names[j], float(sv[j])) for j in order[:topk]]\n",
    "        out.append(pairs)\n",
    "    return out, float(base_val)\n",
    "\n",
    "# collect explanations for flagged *predicted* rows\n",
    "xai_records = []\n",
    "def explain_stage(stage_key, feat_cols, ratio_min_col, flag_col, out_pred_col, base_col):\n",
    "    # rows where stage was predicted AND flagged\n",
    "    if out_pred_col not in pred.columns:\n",
    "        return\n",
    "    m_pred = pred[out_pred_col].notna()\n",
    "    m_flag = pred[flag_col] != \"\"\n",
    "    idx = pred.index[m_pred & m_flag]\n",
    "    if len(idx) == 0:\n",
    "        return\n",
    "\n",
    "    X = pred.loc[idx, feat_cols].copy()\n",
    "    pairs_list, base_val = top_negative_shap(models[stage_key], X, topk=5)\n",
    "\n",
    "    for row_idx, pairs in zip(idx, pairs_list):\n",
    "        rec = {\n",
    "            \"stage\": stage_key.replace(\"_ratio\",\"\").upper(),\n",
    "            \"datetime\": str(pred.at[row_idx, \"datetime\"]),\n",
    "            \"recipe_id\": int(pred.at[row_idx, \"recipe_id\"]),\n",
    "            \"known_level\": int(pred.at[row_idx, \"known_level\"]),\n",
    "            \"predicted_ratio\": float(pred.at[row_idx, f\"{stage_key}_pred\"]),\n",
    "            \"min_ratio\":      float(pred.at[row_idx, ratio_min_col]) if not pd.isna(pred.at[row_idx, ratio_min_col]) else None,\n",
    "            \"actual_ratio\":   float(safe_ratio(truth.at[row_idx, stage_key.replace(\"_ratio\",\"\").join([\"vol_\",\"_out\"])],\n",
    "                                               truth.at[row_idx, base_col])),\n",
    "            \"flag\":           str(pred.at[row_idx, flag_col]),\n",
    "            \"top_neg\":        [{\"feature\": f, \"shap\": v} for (f, v) in pairs],\n",
    "            \"base_value\":     base_val,\n",
    "        }\n",
    "        xai_records.append(rec)\n",
    "\n",
    "# explain ML stages only (press/glaze/kiln)\n",
    "explain_stage(\"press_ratio\", PRESS_FEATS, \"press_ratio_min\", \"press_flag\", \"vol_press_out_pred\", \"vol_start\")\n",
    "explain_stage(\"glaze_ratio\", GLAZE_FEATS, \"glaze_ratio_min\", \"glaze_flag\", \"vol_glaze_out_pred\", \"vol_press_out\")\n",
    "explain_stage(\"kiln_ratio\",  KILN_FEATS,  \"kiln_ratio_min\",  \"kiln_flag\",  \"vol_kiln_out_pred\",  \"vol_glaze_out\")\n",
    "\n",
    "# write explanations (if any; and if SHAP available they have values; otherwise list is empty)\n",
    "if len(xai_records) > 0:\n",
    "    # CSV: flatten top 5 into columns\n",
    "    rows_csv = []\n",
    "    for r in xai_records:\n",
    "        flat = {\n",
    "            \"stage\": r[\"stage\"],\n",
    "            \"datetime\": r[\"datetime\"],\n",
    "            \"recipe_id\": r[\"recipe_id\"],\n",
    "            \"known_level\": r[\"known_level\"],\n",
    "            \"predicted_ratio\": r[\"predicted_ratio\"],\n",
    "            \"min_ratio\": r[\"min_ratio\"],\n",
    "            \"actual_ratio\": r[\"actual_ratio\"],\n",
    "            \"flag\": r[\"flag\"],\n",
    "        }\n",
    "        for k in range(5):\n",
    "            if k < len(r[\"top_neg\"]):\n",
    "                flat[f\"neg{k+1}_feature\"] = r[\"top_neg\"][k][\"feature\"]\n",
    "                flat[f\"neg{k+1}_shap\"]    = r[\"top_neg\"][k][\"shap\"]\n",
    "            else:\n",
    "                flat[f\"neg{k+1}_feature\"] = \"\"\n",
    "                flat[f\"neg{k+1}_shap\"]    = \"\"\n",
    "        rows_csv.append(flat)\n",
    "    pd.DataFrame(rows_csv).to_csv(XAI_OUT_CSV, index=False)\n",
    "    with open(XAI_OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(xai_records, f, indent=2)\n",
    "    print(f\"\\nWrote SHAP explanations:\\n - {XAI_OUT_CSV}\\n - {XAI_OUT_JSON}\")\n",
    "else:\n",
    "    print(\"\\n[INFO] No flagged predicted ML rows or SHAP unavailable ‚Üí no XAI files written.\")\n",
    "\n",
    "# -----------------------\n",
    "# 13) FLAGS-ONLY OUTPUT (NO hardcoded spec flags; ONLY stage flags + Sort@90)\n",
    "# -----------------------\n",
    "stage_cols = [\"press_flag\",\"glaze_flag\",\"kiln_flag\",\"sort_flag\"]\n",
    "any_flag_mask = (pred[stage_cols] != \"\").any(axis=1)\n",
    "\n",
    "flags_cols_order = [\n",
    "    \"datetime\",\"recipe_id\",\"known_level\",\n",
    "    # stage results\n",
    "    \"vol_start\",\"vol_press_out\",\"press_ratio_real\",\"press_ratio_min\",\"press_flag\",\n",
    "    \"vol_glaze_out\",\"glaze_ratio_real\",\"glaze_ratio_min\",\"glaze_flag\",\n",
    "    \"vol_kiln_out\",\"kiln_ratio_real\",\"kiln_ratio_min\",\"kiln_flag\",\n",
    "    \"vol_sort_out\",\"sort_ratio_real\",\"sort_ratio_min\",\"sort_flag\",\n",
    "]\n",
    "flags_cols_order = [c for c in flags_cols_order if c in pred.columns]\n",
    "\n",
    "flags_only = pred.loc[any_flag_mask, flags_cols_order].sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "# If we produced SHAP, attach a compact column per row (top 3 neg features per stage)\n",
    "def topneg_str_for_row(dt, rid, stage):\n",
    "    # find first matching record\n",
    "    for rec in xai_records:\n",
    "        if rec[\"stage\"] == stage and rec[\"datetime\"] == str(dt) and rec[\"recipe_id\"] == int(rid):\n",
    "            parts = [f'{p[\"feature\"]}({p[\"shap\"]:+.4f})' for p in rec[\"top_neg\"][:3]]\n",
    "            return \", \".join(parts)\n",
    "    return \"\"\n",
    "\n",
    "if len(flags_only) > 0 and len(xai_records) > 0:\n",
    "    # add per-stage top-neg strings\n",
    "    flags_only[\"PRESS_topneg\"] = flags_only.apply(\n",
    "        lambda r: topneg_str_for_row(r[\"datetime\"], r[\"recipe_id\"], \"PRESS\"), axis=1) if \"press_flag\" in flags_only.columns else \"\"\n",
    "    flags_only[\"GLAZE_topneg\"] = flags_only.apply(\n",
    "        lambda r: topneg_str_for_row(r[\"datetime\"], r[\"recipe_id\"], \"GLAZE\"), axis=1) if \"glaze_flag\" in flags_only.columns else \"\"\n",
    "    flags_only[\"KILN_topneg\"]  = flags_only.apply(\n",
    "        lambda r: topneg_str_for_row(r[\"datetime\"], r[\"recipe_id\"], \"KILN\"),  axis=1) if \"kiln_flag\" in flags_only.columns else \"\"\n",
    "\n",
    "flags_only.to_csv(FLAGS_ONLY_OUT, index=False)\n",
    "print(f\"\\nWrote flags-only rows:\\n - {FLAGS_ONLY_OUT} (rows with any stage flag)\")\n",
    "print(f\"Flagged rows: {len(flags_only)} of {len(pred)} total\")\n",
    "if len(flags_only) > 0:\n",
    "    print(\"\\nFlags-only preview (first 8):\")\n",
    "    print(flags_only.head(8).to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# 14) PRINT-ONLY REPORTER (console summary)\n",
    "# -----------------------\n",
    "def exists(path):\n",
    "    ok = os.path.exists(path)\n",
    "    if not ok:\n",
    "        print(f\"[WARN] File not found: {path}\")\n",
    "    return ok\n",
    "\n",
    "def print_header(title):\n",
    "    print(\"\\n\" + \"=\"*len(title))\n",
    "    print(title)\n",
    "    print(\"=\"*len(title))\n",
    "\n",
    "MASKED      = OUT_MASKED\n",
    "PREDICTED   = OUT_PRED\n",
    "FRIENDLY    = OUT_FRIENDLY\n",
    "COMPACT_TXT = OUT_COMPACT_T\n",
    "EVAL_PATH   = OUT_EVAL\n",
    "FLAGS_PATH  = FLAGS_ONLY_OUT\n",
    "\n",
    "masked_o   = pd.read_csv(MASKED, parse_dates=[\"datetime\"])    if exists(MASKED)     else None\n",
    "pred_o     = pd.read_csv(PREDICTED, parse_dates=[\"datetime\"])  if exists(PREDICTED) else None\n",
    "friendly_o = pd.read_csv(FRIENDLY, parse_dates=[\"datetime\"])   if exists(FRIENDLY)  else None\n",
    "evaldf_o   = pd.read_csv(EVAL_PATH, parse_dates=[\"datetime\"])  if exists(EVAL_PATH) else None\n",
    "flags_o    = pd.read_csv(FLAGS_PATH, parse_dates=[\"datetime\"]) if exists(FLAGS_PATH) else None\n",
    "\n",
    "print_header(\"FILES SNAPSHOT\")\n",
    "for p in [MASKED, PREDICTED, FRIENDLY, COMPACT_TXT, EVAL_PATH, FLAGS_PATH, XAI_OUT_CSV, XAI_OUT_JSON]:\n",
    "    print((\"‚úì \" if os.path.exists(p) else \"‚úó \") + p)\n",
    "\n",
    "if masked_o is not None and \"known_level\" in masked_o.columns:\n",
    "    print_header(\"MASKED START-POINTS (test rows)\")\n",
    "    labels = {0:\"Start\",1:\"Press\",2:\"Glaze\",3:\"Kiln\",4:\"Full\"}\n",
    "    dist = (masked_o[\"known_level\"].map(labels).value_counts()\n",
    "            .reindex([\"Start\",\"Press\",\"Glaze\",\"Kiln\",\"Full\"])\n",
    "            .fillna(0).astype(int))\n",
    "    print(dist.to_string())\n",
    "\n",
    "if pred_o is not None:\n",
    "    print_header(\"PREDICTION COVERAGE BY STAGE\")\n",
    "    def has(col): return col in pred_o.columns and pred_o[col].notna().any()\n",
    "    cov = {\n",
    "        \"Press_pred_rows\": int(pred_o[\"vol_press_out_pred\"].notna().sum()) if has(\"vol_press_out_pred\") else 0,\n",
    "        \"Glaze_pred_rows\": int(pred_o[\"vol_glaze_out_pred\"].notna().sum()) if has(\"vol_glaze_out_pred\") else 0,\n",
    "        \"Kiln_pred_rows\" : int(pred_o[\"vol_kiln_out_pred\"].notna().sum())  if has(\"vol_kiln_out_pred\")  else 0,\n",
    "        \"Sort_pred_rows\" : int(pred_o[\"vol_sort_out_pred\"].notna().sum())  if has(\"vol_sort_out_pred\")  else 0,\n",
    "        \"Test_total_rows\": len(pred_o)\n",
    "    }\n",
    "    for k,v in cov.items():\n",
    "        print(f\"{k:>18}: {v}\")\n",
    "\n",
    "if friendly_o is not None:\n",
    "    print_header(\"FRIENDLY REPORT (first 8 rows)\")\n",
    "    cols_disp = [\n",
    "        \"datetime\",\"recipe_id\",\"known_level_label\",\"START_amount_ft2\",\n",
    "        \"PRESS_status\",\"PRESS_known_amount_ft2\",\"PRESS_predicted_amount_ft2\",\"PRESS_min_required_ft2\",\"PRESS_flag\",\"PRESS_actual_ft2\",\"PRESS_met_min\",\n",
    "        \"GLAZE_status\",\"GLAZE_known_amount_ft2\",\"GLAZE_predicted_amount_ft2\",\"GLAZE_min_required_ft2\",\"GLAZE_flag\",\"GLAZE_actual_ft2\",\"GLAZE_met_min\",\n",
    "        \"KILN_status\",\"KILN_known_amount_ft2\",\"KILN_predicted_amount_ft2\",\"KILN_min_required_ft2\",\"KILN_flag\",\"KILN_actual_ft2\",\"KILN_met_min\",\n",
    "        \"SORT_status\",\"SORT_known_amount_ft2\",\"SORT_predicted_amount_ft2\",\"SORT_min_required_ft2\",\"SORT_flag\",\"SORT_actual_ft2\",\"SORT_met_min\",\n",
    "    ]\n",
    "    show = [c for c in cols_disp if c in friendly_o.columns]\n",
    "    print(friendly_o[show].head(8).to_string(index=False))\n",
    "\n",
    "if exists(COMPACT_TXT):\n",
    "    print_header(\"COMPACT SUMMARIES (first 8 lines)\")\n",
    "    with open(COMPACT_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 8: break\n",
    "            print(line.rstrip(\"\\n\"))\n",
    "\n",
    "if evaldf_o is not None and not evaldf_o.empty:\n",
    "    print_header(\"RESULTS vs ACTUAL (predicted rows only)\")\n",
    "    def summarize_stage_o(df_stage):\n",
    "        if df_stage.empty: return \"n=0\"\n",
    "        n = len(df_stage)\n",
    "        mae  = pd.to_numeric(df_stage[\"abs_error_ft2\"], errors=\"coerce\").dropna()\n",
    "        mape = pd.to_numeric(df_stage[\"pct_error\"],     errors=\"coerce\").dropna()\n",
    "        comp = (df_stage[\"met_min\"] == \"YES\").mean() if n else np.nan\n",
    "        return f\"n={n}, MAE={mae.mean():.1f} ft¬≤, MAPE={(mape.mean()*100):.2f}%, compliance={comp*100:.1f}%\"\n",
    "    for stg in [\"PRESS\",\"GLAZE\",\"KILN\",\"SORT\"]:\n",
    "        s = summarize_stage_o(evaldf_o[evaldf_o[\"stage\"]==stg])\n",
    "        print(f\"{stg:>5}: {s}\")\n",
    "\n",
    "    print(\"\\nPer-stage eval sample (first 10 rows):\")\n",
    "    keep = [\"stage\",\"datetime\",\"recipe_id\",\"predicted_amount_ft2\",\"min_required_ft2\",\n",
    "            \"actual_amount_ft2\",\"abs_error_ft2\",\"pct_error\",\"met_min\",\"flag_result\"]\n",
    "    print(evaldf_o[keep].head(10).to_string(index=False))\n",
    "\n",
    "if flags_o is not None and not flags_o.empty:\n",
    "    print_header(\"FLAGS SUMMARY\")\n",
    "    print(f\"Flagged rows: {len(flags_o)}\")\n",
    "    # Count each *stage* flag (no spec flags exist anymore)\n",
    "    for c in [\"press_flag\",\"glaze_flag\",\"kiln_flag\",\"sort_flag\"]:\n",
    "        if c in flags_o.columns:\n",
    "            cnt = int((flags_o[c].fillna(\"\") != \"\").sum())\n",
    "            if cnt > 0:\n",
    "                print(f\"{c:>12}: {cnt}\")\n",
    "\n",
    "    print(\"\\nFlags-only preview (first 8):\")\n",
    "    print(flags_o.head(8).to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# 15) SAVE TRAINED BUNDLE FOR UI\n",
    "# -----------------------\n",
    "import joblib, sklearn\n",
    "bundle = {\n",
    "    \"models\": models,  # sklearn Pipelines per stage\n",
    "    \"stage_features\": {\n",
    "        \"press_ratio\": PRESS_FEATS,\n",
    "        \"glaze_ratio\": GLAZE_FEATS,\n",
    "        \"kiln_ratio\":  KILN_FEATS\n",
    "    },\n",
    "    \"config\": {\n",
    "        \"THRESHOLD_MARGIN\": THRESHOLD_MARGIN,\n",
    "        \"SORT_MIN\": SORT_MIN,\n",
    "        \"SORT_DEFAULT\": SORT_DEFAULT,\n",
    "        \"SORT_MAX\": SORT_MAX\n",
    "    },\n",
    "    \"recipe_setpoints\": RECIPE_SETPOINTS,\n",
    "    \"meta\": {\n",
    "        \"created_at_utc\": datetime.utcnow().isoformat(timespec=\"seconds\"),\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"notes\": \"RF models with per-stage features; Sort rule at 90% min; SHAP XAI optional\"\n",
    "    }\n",
    "}\n",
    "joblib.dump(bundle, BUNDLE_PATH)\n",
    "print(f\"\\n‚úÖ Saved model bundle ‚Üí {BUNDLE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
