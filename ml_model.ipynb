{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebeb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 rows from tiles9.csv\n",
      "Train: 425 | Test: 75\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sparse_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 210\u001b[0m\n\u001b[1;32m    208\u001b[0m X \u001b[38;5;241m=\u001b[39m tdf\u001b[38;5;241m.\u001b[39mloc[mask, feats]\n\u001b[1;32m    209\u001b[0m y \u001b[38;5;241m=\u001b[39m tdf\u001b[38;5;241m.\u001b[39mloc[mask, target]\n\u001b[0;32m--> 210\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mmake_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m    212\u001b[0m models[target] \u001b[38;5;241m=\u001b[39m pipe\n",
      "Cell \u001b[0;32mIn[4], line 176\u001b[0m, in \u001b[0;36mmake_pipe\u001b[0;34m(feat_cols)\u001b[0m\n\u001b[1;32m    172\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m feat_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipe_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgloss_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m    173\u001b[0m num_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m feat_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_cols]\n\u001b[1;32m    174\u001b[0m cat_pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m    175\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpute\u001b[39m\u001b[38;5;124m\"\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m--> 176\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mohe\u001b[39m\u001b[38;5;124m\"\u001b[39m,    \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m),\n\u001b[1;32m    177\u001b[0m ])\n\u001b[1;32m    178\u001b[0m num_pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m    179\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpute\u001b[39m\u001b[38;5;124m\"\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    180\u001b[0m ])\n\u001b[1;32m    181\u001b[0m pre \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m    182\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    183\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m, cat_pipe, cat_cols),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m     remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'sparse_out'"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# TILE LINE — Stage Predictions (No Anomaly)\n",
    "# - Data: tiles9.csv  (new schema)\n",
    "# - Drops `datetime` for model training\n",
    "# - Stage models: RandomForest (press/glaze/kiln)\n",
    "# - Predicts forward-missing stages only\n",
    "# - Min thresholds = (pred_ratio - 0.03); Sort min fixed at 0.90\n",
    "# - Outputs CSV reports + joblib bundle for UI\n",
    "# =========================================\n",
    "\n",
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "DATA_PATH    = \"tiles9.csv\"  # <— using tiles9.csv\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE    = 0.15\n",
    "\n",
    "# Staged masking mix (sum to 1.0) for test rows:\n",
    "# 0 = Start only, 1 = up to Press, 2 = up to Glaze, 3 = up to Kiln, 4 = Full known\n",
    "MASK_PROBS = [0.30, 0.25, 0.25, 0.15, 0.05]\n",
    "\n",
    "# Sort policy (rule-only)\n",
    "SORT_MIN     = 0.90\n",
    "SORT_DEFAULT = 0.90\n",
    "SORT_MAX     = 0.92\n",
    "\n",
    "# per-stage min margin around ML predictions\n",
    "THRESHOLD_MARGIN = 0.03\n",
    "\n",
    "# filenames\n",
    "OUT_MASKED     = \"tiles_staged_test_input.csv\"\n",
    "OUT_PRED       = \"tiles_staged_test_predictions.csv\"\n",
    "OUT_FRIENDLY   = \"tiles_predictions_friendly.csv\"\n",
    "OUT_COMPACT_C  = \"tiles_predictions_compact.csv\"\n",
    "OUT_COMPACT_T  = \"tiles_predictions_compact.txt\"\n",
    "OUT_EVAL       = \"tiles_predictions_eval.csv\"\n",
    "FLAGS_ONLY_OUT = \"tiles_flags_only.csv\"\n",
    "BUNDLE_PATH    = \"ml_model.joblib\"\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def safe_ratio(num, den):\n",
    "    num = pd.to_numeric(num, errors=\"coerce\")\n",
    "    den = pd.to_numeric(den, errors=\"coerce\")\n",
    "    r = np.where((den <= 0) | pd.isna(den), np.nan, num / den)\n",
    "    return np.clip(r, 0.0, 1.0)\n",
    "\n",
    "def clip01(x):\n",
    "    return np.minimum(1.0, np.maximum(0.0, x))\n",
    "\n",
    "def volume_from_ratio(prev_vol, ratio, round_to_int=True):\n",
    "    v = prev_vol * ratio\n",
    "    return np.rint(v) if round_to_int else v\n",
    "\n",
    "def as_int_nullable(values):\n",
    "    s = pd.Series(values)\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.round().astype(\"Int64\")\n",
    "\n",
    "def met_min_str(pred_mask, actual_series, minreq_series):\n",
    "    actual = pd.to_numeric(actual_series, errors=\"coerce\").astype(float)\n",
    "    minreq = pd.to_numeric(minreq_series,  errors=\"coerce\").astype(float)\n",
    "    a = actual.to_numpy()\n",
    "    m = minreq.to_numpy()\n",
    "    pred_arr = np.asarray(pred_mask, dtype=bool)\n",
    "    has_both = (~np.isnan(a)) & (~np.isnan(m))\n",
    "    met = a >= m\n",
    "    out = np.full(len(pred_arr), \"\", dtype=object)\n",
    "    idx = pred_arr\n",
    "    out[idx] = np.where(has_both[idx], np.where(met[idx], \"YES\", \"NO\"), \"\")\n",
    "    return pd.Series(out, index=actual_series.index)\n",
    "\n",
    "def fmt_int(x):\n",
    "    try:\n",
    "        v = pd.to_numeric(x)\n",
    "        if pd.isna(v): return \"-\"\n",
    "        return f\"{int(round(float(v))):,}\"\n",
    "    except Exception:\n",
    "        return \"-\"\n",
    "\n",
    "# -----------------------\n",
    "# 1) LOAD\n",
    "# -----------------------\n",
    "# We parse datetime (for reporting only) but DROP it for training features.\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"datetime\"])\n",
    "print(f\"Loaded {len(df)} rows from {DATA_PATH}\")\n",
    "\n",
    "required_cols = [\n",
    "    # identifiers & context\n",
    "    \"datetime\",\"recipe_id\",\"gloss_type\",\"gloss_amount_target_g_per_tile\",\n",
    "    # volumes\n",
    "    \"vol_start\",\"vol_press_out\",\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\",\n",
    "    # press/glaze controls\n",
    "    \"target_pressure\",\"actual_pressure\",\"layers_tossed\",\"desired_thickness\",\n",
    "    # recipe setpoints (context)\n",
    "    \"recipe_air_cooling\",\"recipe_moisture\",\"recipe_air_flow\",\"recipe_max_temp\",\"recipe_humidity\",\n",
    "    # kiln actuals (controls)\n",
    "    \"kiln_air_cooling\",\"kiln_moisture\",\"kiln_air_flow\",\"kiln_max_temp\",\"kiln_humidity\",\n",
    "    # deltas (actual − setpoint)\n",
    "    \"delta_air_cooling\",\"delta_moisture\",\"delta_air_flow\",\"delta_max_temp\",\"delta_humidity\",\n",
    "]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# enforce monotonic safety\n",
    "df[\"vol_press_out\"] = np.minimum(df[\"vol_press_out\"], df[\"vol_start\"])\n",
    "df[\"vol_glaze_out\"] = np.minimum(df[\"vol_glaze_out\"], df[\"vol_press_out\"])\n",
    "df[\"vol_kiln_out\"]  = np.minimum(df[\"vol_kiln_out\"],  df[\"vol_glaze_out\"])\n",
    "df[\"vol_sort_out\"]  = np.minimum(df[\"vol_sort_out\"],  df[\"vol_kiln_out\"])\n",
    "\n",
    "# targets\n",
    "df[\"press_ratio\"] = safe_ratio(df[\"vol_press_out\"], df[\"vol_start\"])\n",
    "df[\"glaze_ratio\"] = safe_ratio(df[\"vol_glaze_out\"], df[\"vol_press_out\"])\n",
    "df[\"kiln_ratio\"]  = safe_ratio(df[\"vol_kiln_out\"],  df[\"vol_glaze_out\"])\n",
    "df[\"sort_ratio\"]  = safe_ratio(df[\"vol_sort_out\"],  df[\"vol_kiln_out\"])\n",
    "\n",
    "# -----------------------\n",
    "# 2) FEATURE SETS (stage-specific)  — datetime is NOT included\n",
    "# -----------------------\n",
    "PRESS_FEATS = [\n",
    "    \"vol_start\",\n",
    "    \"actual_pressure\",\"target_pressure\",\n",
    "    \"layers_tossed\",\n",
    "    \"gloss_type\",\"gloss_amount_target_g_per_tile\",\n",
    "    \"desired_thickness\",\n",
    "    \"recipe_id\",\n",
    "]\n",
    "GLAZE_FEATS = [\n",
    "    \"vol_press_out\",\n",
    "    \"actual_pressure\",\"target_pressure\",\n",
    "    \"layers_tossed\",\n",
    "    \"gloss_type\",\"gloss_amount_target_g_per_tile\",\n",
    "    \"desired_thickness\",\n",
    "    \"recipe_id\",\n",
    "]\n",
    "KILN_FEATS  = [\n",
    "    \"vol_glaze_out\",\n",
    "    \"desired_thickness\",\n",
    "    # recipe setpoints (context)\n",
    "    \"recipe_air_cooling\",\"recipe_moisture\",\"recipe_air_flow\",\"recipe_max_temp\",\"recipe_humidity\",\n",
    "    # kiln actuals (controls)\n",
    "    \"kiln_air_cooling\",\"kiln_moisture\",\"kiln_air_flow\",\"kiln_max_temp\",\"kiln_humidity\",\n",
    "    # deltas (actual − setpoint)\n",
    "    \"delta_air_cooling\",\"delta_moisture\",\"delta_air_flow\",\"delta_max_temp\",\"delta_humidity\",\n",
    "    # identifiers\n",
    "    \"gloss_type\",\"recipe_id\",\n",
    "]\n",
    "\n",
    "STAGE_TO_FEATS = {\n",
    "    \"press_ratio\": PRESS_FEATS,\n",
    "    \"glaze_ratio\": GLAZE_FEATS,\n",
    "    \"kiln_ratio\":  KILN_FEATS,\n",
    "}\n",
    "\n",
    "def make_pipe(feat_cols):\n",
    "    cat_cols = [c for c in feat_cols if c in (\"recipe_id\",\"gloss_type\")]\n",
    "    num_cols = [c for c in feat_cols if c not in cat_cols]\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\",    OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ])\n",
    "    num_pipe = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_pipe, cat_cols),\n",
    "            (\"num\", num_pipe, num_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=500, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    return Pipeline([(\"pre\", pre), (\"rf\", model)])\n",
    "\n",
    "# -----------------------\n",
    "# 3) TRAIN / TEST SPLIT\n",
    "# -----------------------\n",
    "train_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df  = test_df.reset_index(drop=True)\n",
    "print(f\"Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# -----------------------\n",
    "# 4) FIT MODELS (datetime dropped implicitly by feature lists)\n",
    "# -----------------------\n",
    "models = {}\n",
    "for target, feats in STAGE_TO_FEATS.items():\n",
    "    tdf = train_df.copy()\n",
    "    mask = ~tdf[target].isna()\n",
    "    X = tdf.loc[mask, feats]\n",
    "    y = tdf.loc[mask, target]\n",
    "    pipe = make_pipe(feats)\n",
    "    pipe.fit(X, y)\n",
    "    models[target] = pipe\n",
    "    y_pred = clip01(pipe.predict(X))\n",
    "    print(f\"[FIT] {target}: R2={r2_score(y, y_pred):.3f} MAE={mean_absolute_error(y, y_pred):.4f} n={len(X)}\")\n",
    "\n",
    "# -----------------------\n",
    "# 5) STAGED MASKING (various prediction starting points on TEST)\n",
    "# -----------------------\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "levels = rng.choice([0,1,2,3,4], size=len(test_df), p=MASK_PROBS)\n",
    "masked = test_df.copy()\n",
    "masked[\"known_level\"] = levels\n",
    "\n",
    "for i, lvl in enumerate(levels):\n",
    "    if lvl < 1:\n",
    "        masked.loc[i, [\"vol_press_out\",\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\"]] = np.nan\n",
    "    elif lvl < 2:\n",
    "        masked.loc[i, [\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\"]] = np.nan\n",
    "    elif lvl < 3:\n",
    "        masked.loc[i, [\"vol_kiln_out\",\"vol_sort_out\"]] = np.nan\n",
    "    elif lvl < 4:\n",
    "        masked.loc[i, [\"vol_sort_out\"]] = np.nan\n",
    "\n",
    "truth = test_df[[\"vol_start\",\"vol_press_out\",\"vol_glaze_out\",\"vol_kiln_out\",\"vol_sort_out\"]].copy()\n",
    "\n",
    "print(\"\\nMasked start-points (test):\")\n",
    "print(pd.Series(levels).map({0:\"Start\",1:\"Press\",2:\"Glaze\",3:\"Kiln\",4:\"Full\"}).value_counts().sort_index().to_string())\n",
    "\n",
    "# -----------------------\n",
    "# 6) PREDICT ONLY MISSING FORWARD + build min thresholds\n",
    "# -----------------------\n",
    "pred = masked.copy()\n",
    "\n",
    "def predict_stage(mdf, stage_key, feat_cols, prev_col, out_col):\n",
    "    need = mdf[out_col].isna() & mdf[prev_col].notna()\n",
    "    if need.any():\n",
    "        r = clip01(models[stage_key].predict(mdf.loc[need, feat_cols]))\n",
    "        mdf.loc[need, f\"{stage_key}_pred\"] = r\n",
    "        mdf.loc[need, f\"{stage_key}_min\"]  = clip01(r - THRESHOLD_MARGIN)\n",
    "        mdf.loc[need, f\"{out_col}_pred\"]   = volume_from_ratio(mdf.loc[need, prev_col].values, r, round_to_int=True)\n",
    "        mdf.loc[need, out_col]             = mdf.loc[need, f\"{out_col}_pred\"]\n",
    "    return mdf\n",
    "\n",
    "# Press -> predict vol_press_out if missing\n",
    "pred = predict_stage(pred, \"press_ratio\", PRESS_FEATS, prev_col=\"vol_start\",     out_col=\"vol_press_out\")\n",
    "pred[\"vol_press_out\"] = np.minimum(pred[\"vol_press_out\"], pred[\"vol_start\"])\n",
    "\n",
    "# Glaze -> predict vol_glaze_out if missing\n",
    "pred = predict_stage(pred, \"glaze_ratio\", GLAZE_FEATS, prev_col=\"vol_press_out\", out_col=\"vol_glaze_out\")\n",
    "pred[\"vol_glaze_out\"] = np.minimum(pred[\"vol_glaze_out\"], pred[\"vol_press_out\"])\n",
    "\n",
    "# Kiln -> predict vol_kiln_out if missing\n",
    "pred = predict_stage(pred, \"kiln_ratio\",  KILN_FEATS,  prev_col=\"vol_glaze_out\", out_col=\"vol_kiln_out\")\n",
    "pred[\"vol_kiln_out\"]  = np.minimum(pred[\"vol_kiln_out\"],  pred[\"vol_glaze_out\"])\n",
    "\n",
    "# Sort (rule): min fixed at 90%, ratio default 0.90–0.92 clamp\n",
    "need_sort = pred[\"vol_sort_out\"].isna() & pred[\"vol_kiln_out\"].notna()\n",
    "if need_sort.any():\n",
    "    r = np.clip(np.full(need_sort.sum(), SORT_DEFAULT), SORT_MIN, SORT_MAX)\n",
    "    pred.loc[need_sort, \"sort_ratio_pred\"] = r\n",
    "    pred.loc[need_sort, \"sort_ratio_min\"]  = SORT_MIN\n",
    "    pred.loc[need_sort, \"vol_sort_out_pred\"] = volume_from_ratio(pred.loc[need_sort, \"vol_kiln_out\"].values, r, round_to_int=True)\n",
    "    pred.loc[need_sort, \"vol_sort_out\"] = pred.loc[need_sort, \"vol_sort_out_pred\"]\n",
    "pred[\"vol_sort_out\"] = np.minimum(pred[\"vol_sort_out\"], pred[\"vol_kiln_out\"])\n",
    "\n",
    "# -----------------------\n",
    "# 7) ACCURACY (predicted rows only)\n",
    "# -----------------------\n",
    "def stage_metrics(stage_out, base_col, pred_out_col):\n",
    "    tr = safe_ratio(truth[stage_out].to_numpy(), truth[base_col].to_numpy())\n",
    "    pr = safe_ratio(pred[stage_out].to_numpy(),  pred[base_col].to_numpy())\n",
    "    if pred_out_col not in pred.columns:\n",
    "        return dict(n=0, R2=np.nan, MAE=np.nan)\n",
    "    mask = pred[pred_out_col].notna()\n",
    "    if mask.any():\n",
    "        return dict(n=int(mask.sum()),\n",
    "                    R2=float(r2_score(tr[mask], pr[mask])),\n",
    "                    MAE=float(mean_absolute_error(tr[mask], pr[mask])))\n",
    "    return dict(n=0, R2=np.nan, MAE=np.nan)\n",
    "\n",
    "print(\"\\n=== ACCURACY (predicted rows only) ===\")\n",
    "print(\"Press:\", stage_metrics(\"vol_press_out\", \"vol_start\",     \"vol_press_out_pred\"))\n",
    "print(\"Glaze:\", stage_metrics(\"vol_glaze_out\", \"vol_press_out\", \"vol_glaze_out_pred\"))\n",
    "print(\"Kiln :\", stage_metrics(\"vol_kiln_out\",  \"vol_glaze_out\", \"vol_kiln_out_pred\"))\n",
    "\n",
    "# -----------------------\n",
    "# 8) REALIZED RATIOS & STAGE FLAGS (from min thresholds)\n",
    "# -----------------------\n",
    "pred[\"press_ratio_real\"] = safe_ratio(pred[\"vol_press_out\"], pred[\"vol_start\"])\n",
    "pred[\"glaze_ratio_real\"] = safe_ratio(pred[\"vol_glaze_out\"], pred[\"vol_press_out\"])\n",
    "pred[\"kiln_ratio_real\"]  = safe_ratio(pred[\"vol_kiln_out\"],  pred[\"vol_glaze_out\"])\n",
    "pred[\"sort_ratio_real\"]  = safe_ratio(pred[\"vol_sort_out\"],  pred[\"vol_kiln_out\"])\n",
    "\n",
    "for nm in [\"press_ratio_min\",\"glaze_ratio_min\",\"kiln_ratio_min\",\"sort_ratio_min\"]:\n",
    "    if nm not in pred.columns: pred[nm] = np.nan\n",
    "pred.loc[pred[\"vol_kiln_out\"].notna(), \"sort_ratio_min\"] = SORT_MIN\n",
    "\n",
    "pred[\"press_flag\"] = np.where(\n",
    "    (pred[\"press_ratio_min\"].notna()) & (pred[\"press_ratio_real\"] < pred[\"press_ratio_min\"]),\n",
    "    \"LOW_PRESS_YIELD\", \"\"\n",
    ")\n",
    "pred[\"glaze_flag\"] = np.where(\n",
    "    (pred[\"glaze_ratio_min\"].notna()) & (pred[\"glaze_ratio_real\"] < pred[\"glaze_ratio_min\"]),\n",
    "    \"LOW_GLAZE_YIELD\", \"\"\n",
    ")\n",
    "pred[\"kiln_flag\"] = np.where(\n",
    "    (pred[\"kiln_ratio_min\"].notna()) & (pred[\"kiln_ratio_real\"] < pred[\"kiln_ratio_min\"]),\n",
    "    \"LOW_KILN_YIELD\", \"\"\n",
    ")\n",
    "pred[\"sort_flag\"] = np.where(pred[\"sort_ratio_real\"] < SORT_MIN, \"SORT_BELOW_90\", \"\")\n",
    "\n",
    "# -----------------------\n",
    "# 9) FRIENDLY REPORT (known vs predicted + min + flag + correctness)\n",
    "# -----------------------\n",
    "LEVEL_LABELS = {0:\"Start only\",1:\"Up to Press\",2:\"Up to Glaze\",3:\"Up to Kiln\",4:\"Full known\"}\n",
    "press_known = masked[\"vol_press_out\"].notna()\n",
    "glaze_known = masked[\"vol_glaze_out\"].notna()\n",
    "kiln_known  = masked[\"vol_kiln_out\"].notna()\n",
    "sort_known  = masked[\"vol_sort_out\"].notna()\n",
    "press_pred  = pred[\"vol_press_out_pred\"].notna()\n",
    "glaze_pred  = pred[\"vol_glaze_out_pred\"].notna()\n",
    "kiln_pred   = pred[\"vol_kiln_out_pred\"].notna()\n",
    "sort_pred   = pred[\"vol_sort_out_pred\"].notna()\n",
    "\n",
    "press_min_vol_num = pred[\"press_ratio_min\"] * pred[\"vol_start\"]\n",
    "glaze_min_vol_num = pred[\"glaze_ratio_min\"] * pred[\"vol_press_out\"]\n",
    "kiln_min_vol_num  = pred[\"kiln_ratio_min\"]  * pred[\"vol_glaze_out\"]\n",
    "sort_min_vol_num  = SORT_MIN * pred[\"vol_kiln_out\"]\n",
    "\n",
    "friendly = pd.DataFrame({\n",
    "    \"datetime\": pred[\"datetime\"],\n",
    "    \"recipe_id\": pred[\"recipe_id\"],\n",
    "    \"known_level\": pred[\"known_level\"],\n",
    "    \"known_level_label\": pd.Series(pred[\"known_level\"]).map(LEVEL_LABELS),\n",
    "    \"START_amount_ft2\": as_int_nullable(pred[\"vol_start\"]),\n",
    "})\n",
    "\n",
    "# PRESS\n",
    "friendly[\"PRESS_status\"]               = np.where(press_known, \"known\", np.where(press_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"PRESS_known_amount_ft2\"]     = as_int_nullable(np.where(press_known, pred[\"vol_press_out\"], np.nan))\n",
    "friendly[\"PRESS_predicted_amount_ft2\"] = as_int_nullable(np.where(press_pred,  pred[\"vol_press_out_pred\"], np.nan))\n",
    "friendly[\"PRESS_min_required_ft2\"]     = as_int_nullable(np.where(press_pred,  press_min_vol_num, np.nan))\n",
    "friendly[\"PRESS_flag\"]                 = np.where(press_pred,  pred[\"press_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"PRESS_actual_ft2\"]           = as_int_nullable(truth[\"vol_press_out\"])\n",
    "friendly[\"PRESS_met_min\"]              = met_min_str(press_pred, friendly[\"PRESS_actual_ft2\"], friendly[\"PRESS_min_required_ft2\"])\n",
    "\n",
    "# GLAZE\n",
    "friendly[\"GLAZE_status\"]               = np.where(glaze_known, \"known\", np.where(glaze_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"GLAZE_known_amount_ft2\"]     = as_int_nullable(np.where(glaze_known, pred[\"vol_glaze_out\"], np.nan))\n",
    "friendly[\"GLAZE_predicted_amount_ft2\"] = as_int_nullable(np.where(glaze_pred,  pred[\"vol_glaze_out_pred\"], np.nan))\n",
    "friendly[\"GLAZE_min_required_ft2\"]     = as_int_nullable(np.where(glaze_pred,  glaze_min_vol_num, np.nan))\n",
    "friendly[\"GLAZE_flag\"]                 = np.where(glaze_pred,  pred[\"glaze_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"GLAZE_actual_ft2\"]           = as_int_nullable(truth[\"vol_glaze_out\"])\n",
    "friendly[\"GLAZE_met_min\"]              = met_min_str(glaze_pred, friendly[\"GLAZE_actual_ft2\"], friendly[\"GLAZE_min_required_ft2\"])\n",
    "\n",
    "# KILN\n",
    "friendly[\"KILN_status\"]               = np.where(kiln_known, \"known\", np.where(kiln_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"KILN_known_amount_ft2\"]     = as_int_nullable(np.where(kiln_known, pred[\"vol_kiln_out\"], np.nan))\n",
    "friendly[\"KILN_predicted_amount_ft2\"] = as_int_nullable(np.where(kiln_pred,  pred[\"vol_kiln_out_pred\"], np.nan))\n",
    "friendly[\"KILN_min_required_ft2\"]     = as_int_nullable(np.where(kiln_pred,  kiln_min_vol_num, np.nan))\n",
    "friendly[\"KILN_flag\"]                 = np.where(kiln_pred,  pred[\"kiln_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"KILN_actual_ft2\"]           = as_int_nullable(truth[\"vol_kiln_out\"])\n",
    "friendly[\"KILN_met_min\"]              = met_min_str(kiln_pred, friendly[\"KILN_actual_ft2\"], friendly[\"KILN_min_required_ft2\"])\n",
    "\n",
    "# SORT (rule)\n",
    "friendly[\"SORT_status\"]               = np.where(sort_known, \"known\", np.where(sort_pred, \"predicted\", \"unknown\"))\n",
    "friendly[\"SORT_known_amount_ft2\"]     = as_int_nullable(np.where(sort_known, pred[\"vol_sort_out\"], np.nan))\n",
    "friendly[\"SORT_predicted_amount_ft2\"] = as_int_nullable(np.where(sort_pred,  pred[\"vol_sort_out_pred\"], np.nan))\n",
    "friendly[\"SORT_min_required_ft2\"]     = as_int_nullable(np.where(sort_pred,  sort_min_vol_num, np.nan))\n",
    "friendly[\"SORT_flag\"]                 = np.where(sort_pred,  pred[\"sort_flag\"].fillna(\"\"), \"\")\n",
    "friendly[\"SORT_actual_ft2\"]           = as_int_nullable(truth[\"vol_sort_out\"])\n",
    "friendly[\"SORT_met_min\"]              = met_min_str(sort_pred, friendly[\"SORT_actual_ft2\"], friendly[\"SORT_min_required_ft2\"])\n",
    "\n",
    "friendly = friendly.sort_values(\"datetime\").reset_index(drop=True)\n",
    "friendly.to_csv(OUT_FRIENDLY, index=False)\n",
    "print(f\"\\nWrote friendly per-row report:\\n - {OUT_FRIENDLY}\")\n",
    "\n",
    "# -----------------------\n",
    "# 10) COMPACT ONE-LINE SUMMARY PER ROW\n",
    "# -----------------------\n",
    "def min_volumes_row(row):\n",
    "    press_min = row.get(\"press_ratio_min\", np.nan) * row.get(\"vol_start\", np.nan)\n",
    "    glaze_min = row.get(\"glaze_ratio_min\", np.nan) * row.get(\"vol_press_out\", np.nan)\n",
    "    kiln_min  = row.get(\"kiln_ratio_min\",  np.nan) * row.get(\"vol_glaze_out\", np.nan)\n",
    "    sort_min  = SORT_MIN * row.get(\"vol_kiln_out\", np.nan)\n",
    "    return press_min, glaze_min, kiln_min, sort_min\n",
    "\n",
    "def stage_piece(name, known_val, pred_val, min_vol):\n",
    "    known = not pd.isna(known_val)\n",
    "    predicted = not pd.isna(pred_val)\n",
    "    if known:\n",
    "        return f\"{name} = {fmt_int(known_val)}\"\n",
    "    if predicted:\n",
    "        return f\"{name} = {fmt_int(pred_val)} (pred), min {fmt_int(min_vol)}\"\n",
    "    return f\"{name} = -\"\n",
    "\n",
    "press_known_mask = masked[\"vol_press_out\"].notna()\n",
    "glaze_known_mask = masked[\"vol_glaze_out\"].notna()\n",
    "kiln_known_mask  = masked[\"vol_kiln_out\"].notna()\n",
    "sort_known_mask  = masked[\"vol_sort_out\"].notna()\n",
    "\n",
    "pred[\"__press_pred__\"] = pred[\"vol_press_out_pred\"].notna()\n",
    "pred[\"__glaze_pred__\"] = pred[\"vol_glaze_out_pred\"].notna()\n",
    "pred[\"__kiln_pred__\"]  = pred[\"vol_kiln_out_pred\"].notna()\n",
    "pred[\"__sort_pred__\"]  = pred[\"vol_sort_out_pred\"].notna()\n",
    "\n",
    "lines = []\n",
    "rows = []\n",
    "for i, row in pred.reset_index(drop=True).iterrows():\n",
    "    start_piece = f\"Start = {fmt_int(row['vol_start'])}\"\n",
    "    pmin, gmin, kmin, smin = min_volumes_row(row)\n",
    "\n",
    "    press_piece = stage_piece(\n",
    "        \"Press\",\n",
    "        known_val = pred.loc[i, \"vol_press_out\"] if press_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_press_out_pred\"] if pred[\"__press_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = pmin\n",
    "    )\n",
    "    glaze_piece = stage_piece(\n",
    "        \"Glaze\",\n",
    "        known_val = pred.loc[i, \"vol_glaze_out\"] if glaze_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_glaze_out_pred\"] if pred[\"__glaze_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = gmin\n",
    "    )\n",
    "    kiln_piece = stage_piece(\n",
    "        \"Kiln\",\n",
    "        known_val = pred.loc[i, \"vol_kiln_out\"] if kiln_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_kiln_out_pred\"] if pred[\"__kiln_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = kmin\n",
    "    )\n",
    "    sort_piece = stage_piece(\n",
    "        \"Sort\",\n",
    "        known_val = pred.loc[i, \"vol_sort_out\"] if sort_known_mask.iloc[i] else np.nan,\n",
    "        pred_val  = pred.loc[i, \"vol_sort_out_pred\"] if pred[\"__sort_pred__\"].iloc[i] else np.nan,\n",
    "        min_vol   = smin\n",
    "    )\n",
    "\n",
    "    summary = \"  \".join([start_piece, press_piece, glaze_piece, kiln_piece, sort_piece])\n",
    "    lines.append(summary)\n",
    "    rows.append({\"datetime\": row[\"datetime\"], \"recipe_id\": row[\"recipe_id\"], \"known_level\": row[\"known_level\"], \"summary\": summary})\n",
    "\n",
    "with open(OUT_COMPACT_T, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in lines:\n",
    "        f.write(s + \"\\n\")\n",
    "pd.DataFrame(rows).sort_values(\"datetime\").to_csv(OUT_COMPACT_C, index=False)\n",
    "print(f\"\\nWrote compact summaries:\\n - {OUT_COMPACT_T}\\n - {OUT_COMPACT_C}\")\n",
    "\n",
    "# -----------------------\n",
    "# 11) PER-STAGE EVAL vs ACTUAL\n",
    "# -----------------------\n",
    "def stage_eval(stage, base_col, out_col, pred_out_col, min_ratio_col, fixed_min=None):\n",
    "    if pred_out_col not in pred.columns:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"stage\",\"datetime\",\"recipe_id\",\n",
    "            \"predicted_amount_ft2\",\"min_required_ft2\",\"actual_amount_ft2\",\n",
    "            \"abs_error_ft2\",\"pct_error\",\"met_min\",\"flag_result\"\n",
    "        ])\n",
    "    m = pred[pred_out_col].notna()\n",
    "    if not m.any():\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"stage\",\"datetime\",\"recipe_id\",\n",
    "            \"predicted_amount_ft2\",\"min_required_ft2\",\"actual_amount_ft2\",\n",
    "            \"abs_error_ft2\",\"pct_error\",\"met_min\",\"flag_result\"\n",
    "        ])\n",
    "\n",
    "    min_ratio = pd.to_numeric(pred.loc[m, min_ratio_col], errors=\"coerce\") if fixed_min is None else pd.Series(fixed_min, index=pred.index)[m]\n",
    "    base = pd.to_numeric(pred.loc[m, base_col], errors=\"coerce\")\n",
    "    min_required = min_ratio * base\n",
    "\n",
    "    pred_amt = pd.to_numeric(pred.loc[m, pred_out_col], errors=\"coerce\")\n",
    "    actual_amt = pd.to_numeric(truth.loc[m, out_col], errors=\"coerce\")\n",
    "\n",
    "    abs_err = (pred_amt - actual_amt).abs()\n",
    "    pct_err = abs_err / actual_amt.replace({0: np.nan})\n",
    "\n",
    "    actual_ratio = actual_amt / base.replace({0: np.nan})\n",
    "    flag_result = np.where(actual_ratio < min_ratio, \"FLAG\", \"OK\")\n",
    "    met_min = np.where(actual_amt >= min_required, \"YES\", \"NO\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"stage\": stage,\n",
    "        \"datetime\": pred.loc[m, \"datetime\"],\n",
    "        \"recipe_id\": pred.loc[m, \"recipe_id\"],\n",
    "        \"predicted_amount_ft2\": pred_amt.round().astype(\"Int64\"),\n",
    "        \"min_required_ft2\": min_required.round().astype(\"Int64\"),\n",
    "        \"actual_amount_ft2\": actual_amt.round().astype(\"Int64\"),\n",
    "        \"abs_error_ft2\": abs_err.round().astype(\"Int64\"),\n",
    "        \"pct_error\": pct_err,\n",
    "        \"met_min\": met_min,\n",
    "        \"flag_result\": flag_result\n",
    "    })\n",
    "\n",
    "eval_press = stage_eval(\"PRESS\", base_col=\"vol_start\",     out_col=\"vol_press_out\",\n",
    "                        pred_out_col=\"vol_press_out_pred\", min_ratio_col=\"press_ratio_min\")\n",
    "eval_glaze = stage_eval(\"GLAZE\", base_col=\"vol_press_out\", out_col=\"vol_glaze_out\",\n",
    "                        pred_out_col=\"vol_glaze_out_pred\", min_ratio_col=\"glaze_ratio_min\")\n",
    "eval_kiln  = stage_eval(\"KILN\",  base_col=\"vol_glaze_out\", out_col=\"vol_kiln_out\",\n",
    "                        pred_out_col=\"vol_kiln_out_pred\",  min_ratio_col=\"kiln_ratio_min\")\n",
    "eval_sort  = stage_eval(\"SORT\",  base_col=\"vol_kiln_out\",  out_col=\"vol_sort_out\",\n",
    "                        pred_out_col=\"vol_sort_out_pred\",  min_ratio_col=\"sort_ratio_min\", fixed_min=SORT_MIN)\n",
    "\n",
    "eval_all = pd.concat([eval_press, eval_glaze, eval_kiln, eval_sort], ignore_index=True)\n",
    "eval_all.to_csv(OUT_EVAL, index=False)\n",
    "print(f\"\\nWrote per-stage evaluation vs ACTUAL:\\n - {OUT_EVAL}\")\n",
    "\n",
    "def summarize_stage(df_stage):\n",
    "    if df_stage.empty:\n",
    "        return \"n=0\"\n",
    "    n = len(df_stage)\n",
    "    mae  = pd.to_numeric(df_stage[\"abs_error_ft2\"], errors=\"coerce\").dropna()\n",
    "    mape = pd.to_numeric(df_stage[\"pct_error\"],     errors=\"coerce\").dropna()\n",
    "    comp = (df_stage[\"met_min\"] == \"YES\").mean() if n else np.nan\n",
    "    return f\"n={n}, MAE={mae.mean():.1f} ft², MAPE={(mape.mean()*100):.2f}%, compliance={comp*100:.1f}%\"\n",
    "\n",
    "print(\"\\n=== RESULTS vs ACTUAL (predicted rows) ===\")\n",
    "print(\"PRESS :\", summarize_stage(eval_press))\n",
    "print(\"GLAZE :\", summarize_stage(eval_glaze))\n",
    "print(\"KILN  :\", summarize_stage(eval_kiln))\n",
    "print(\"SORT  :\", summarize_stage(eval_sort))\n",
    "\n",
    "# Also write the filled test & masked inputs for reference\n",
    "pred.to_csv(OUT_PRED, index=False)\n",
    "masked.to_csv(OUT_MASKED, index=False)\n",
    "print(f\"\\nWrote:\\n - {OUT_MASKED}\\n - {OUT_PRED}\")\n",
    "\n",
    "# Quick friendly preview\n",
    "print(\"\\nFriendly preview (first 6 rows):\")\n",
    "cols = [\n",
    "    \"datetime\",\"recipe_id\",\"known_level_label\",\"START_amount_ft2\",\n",
    "    \"PRESS_status\",\"PRESS_known_amount_ft2\",\"PRESS_predicted_amount_ft2\",\"PRESS_min_required_ft2\",\"PRESS_flag\",\"PRESS_actual_ft2\",\"PRESS_met_min\",\n",
    "    \"GLAZE_status\",\"GLAZE_known_amount_ft2\",\"GLAZE_predicted_amount_ft2\",\"GLAZE_min_required_ft2\",\"GLAZE_flag\",\"GLAZE_actual_ft2\",\"GLAZE_met_min\",\n",
    "    \"KILN_status\",\"KILN_known_amount_ft2\",\"KILN_predicted_amount_ft2\",\"KILN_min_required_ft2\",\"KILN_flag\",\"KILN_actual_ft2\",\"KILN_met_min\",\n",
    "    \"SORT_status\",\"SORT_known_amount_ft2\",\"SORT_predicted_amount_ft2\",\"SORT_min_required_ft2\",\"SORT_flag\",\"SORT_actual_ft2\",\"SORT_met_min\",\n",
    "]\n",
    "print(friendly[cols].head(6).to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# 12) FLAGS-ONLY OUTPUT (rows with any stage flag)\n",
    "# -----------------------\n",
    "stage_cols = [\"press_flag\",\"glaze_flag\",\"kiln_flag\",\"sort_flag\"]\n",
    "any_flag_mask = (pred[stage_cols] != \"\").any(axis=1)\n",
    "\n",
    "flags_cols_order = [\n",
    "    \"datetime\",\"recipe_id\",\"known_level\",\n",
    "    \"vol_start\",\"vol_press_out\",\"press_ratio_real\",\"press_ratio_min\",\"press_flag\",\n",
    "    \"vol_glaze_out\",\"glaze_ratio_real\",\"glaze_ratio_min\",\"glaze_flag\",\n",
    "    \"vol_kiln_out\",\"kiln_ratio_real\",\"kiln_ratio_min\",\"kiln_flag\",\n",
    "    \"vol_sort_out\",\"sort_ratio_real\",\"sort_ratio_min\",\"sort_flag\",\n",
    "]\n",
    "flags_cols_order = [c for c in flags_cols_order if c in pred.columns]\n",
    "\n",
    "flags_only = pred.loc[any_flag_mask, flags_cols_order].sort_values(\"datetime\").reset_index(drop=True)\n",
    "flags_only.to_csv(FLAGS_ONLY_OUT, index=False)\n",
    "print(f\"\\nWrote flags-only rows:\\n - {FLAGS_ONLY_OUT} (rows with any stage flag)\")\n",
    "print(f\"Flagged rows: {len(flags_only)} of {len(pred)} total\")\n",
    "if len(flags_only) > 0:\n",
    "    print(\"\\nFlags-only preview (first 8):\")\n",
    "    print(flags_only.head(8).to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# 13) SAVE TRAINED BUNDLE FOR UI\n",
    "# -----------------------\n",
    "import joblib, sklearn\n",
    "bundle = {\n",
    "    \"models\": models,  # sklearn Pipelines per stage\n",
    "    \"stage_features\": {\n",
    "        \"press_ratio\": PRESS_FEATS,\n",
    "        \"glaze_ratio\": GLAZE_FEATS,\n",
    "        \"kiln_ratio\":  KILN_FEATS\n",
    "    },\n",
    "    \"config\": {\n",
    "        \"THRESHOLD_MARGIN\": THRESHOLD_MARGIN,\n",
    "        \"SORT_MIN\": SORTa_MIN,\n",
    "        \"SORT_DEFAULT\": SORT_DEFAULT,\n",
    "        \"SORT_MAX\": SORT_MAX\n",
    "    },\n",
    "    \"meta\": {\n",
    "        \"created_at_utc\": datetime.utcnow().isoformat(timespec=\"seconds\"),\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"notes\": \"RF models on tiles9 schema; Sort rule at 90% min; datetime excluded from features\"\n",
    "    }\n",
    "}\n",
    "joblib.dump(bundle, BUNDLE_PATH)\n",
    "joblib.dump(bundle, \"ml_model.joblib\")  # optional for Pyodide UI\n",
    "print(f\"\\nSaved model bundle → {BUNDLE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a391f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load\n",
    "eval_df = pd.read_csv(\"tiles_predictions_eval.csv\")\n",
    "compact_df = pd.read_csv(\"tiles_predictions_compact.csv\")\n",
    "\n",
    "print(\"Loaded\", len(eval_df), \"evaluation rows\")\n",
    "print(eval_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
